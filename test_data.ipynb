{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32060f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Got data from exchange 'HOSE'\n",
      "üéâ Saved 267 rows to MWG_2024-01-01_to_2025-01-31_tv.csv\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "START, END = datetime(2024,1,1), datetime(2025,1,31)\n",
    "\n",
    "# --- 1) Try tvDatafeed with different exchange codes ---\n",
    "tv = TvDatafeed()\n",
    "exchanges = [\"HOSE\", \"HSX\", \"VN\", \"UPCOM\", \"HNX\"]\n",
    "df = None\n",
    "\n",
    "for exch in exchanges:\n",
    "    try:\n",
    "        tmp = tv.get_hist(\n",
    "            symbol   = \"MWG\",\n",
    "            exchange = exch,\n",
    "            interval = Interval.in_daily,\n",
    "            n_bars   = 400\n",
    "        )\n",
    "        if tmp is not None and not tmp.empty:\n",
    "            df = tmp\n",
    "            print(f\"‚úÖ Got data from exchange '{exch}'\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  tvDatafeed error for {exch}: {e}\")\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # strip timezone, filter the date window\n",
    "    df.index = df.index.tz_localize(None)\n",
    "    df = df.loc[\"2024-01-01\":\"2025-01-31\"]\n",
    "    df.to_csv(\"MWG_2024-01-01_to_2025-01-31_tv.csv\")\n",
    "    print(f\"üéâ Saved {len(df)} rows to MWG_2024-01-01_to_2025-01-31_tv.csv\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  tvDatafeed failed for all exchanges; falling back to scraping‚Ä¶\")\n",
    "\n",
    "    # --- 2) Fallback: scrape Vietstock‚Äôs ‚ÄòL·ªãch s·ª≠ gi√°‚Äô table ---\n",
    "    def fetch_page(page):\n",
    "        url = (\n",
    "          \"https://finance.vietstock.vn/companies/mwg/mobile-world-group/\"\n",
    "          \"lich-su-gia?languageid=2&page=\" + str(page)\n",
    "        )\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "        tbl  = soup.find(\"table\", class_=\"tblData\")\n",
    "        if not tbl:\n",
    "            return []\n",
    "        rows = []\n",
    "        for tr in tbl.tbody.find_all(\"tr\"):\n",
    "            cols = [td.text.strip().replace(\",\", \"\") for td in tr.find_all(\"td\")]\n",
    "            dt = datetime.strptime(cols[0], \"%d/%m/%Y\")\n",
    "            if dt < START:\n",
    "                return []\n",
    "            rows.append([dt, float(cols[1]), float(cols[2]), float(cols[3]), float(cols[4]), int(cols[5])])\n",
    "        return rows\n",
    "\n",
    "    all_rows = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        page_rows = fetch_page(page)\n",
    "        if not page_rows:\n",
    "            break\n",
    "        all_rows.extend(page_rows)\n",
    "        page += 1\n",
    "\n",
    "    # Build and save DataFrame\n",
    "    df2 = pd.DataFrame(all_rows, columns=[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
    "    df2 = df2.set_index(\"Date\").sort_index()\n",
    "    df2.to_csv(\"MWG_2024-01-01_to_2025-01-31_vietstock.csv\")\n",
    "    print(f\"üéâ Scraped {len(df2)} rows to MWG_2024-01-01_to_2025-01-31_vietstock.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc809afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Saved 267 rows to VNINDEX_2024-01-01_to_2025-01-31_tv.csv\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "START, END = datetime(2024,1,1), datetime(2025,1,31)\n",
    "\n",
    "# --- 1) Th·ª≠ tvDatafeed v·ªõi VN-Index ---\n",
    "tv = TvDatafeed()\n",
    "# Tr√™n TradingView, VN-Index th∆∞·ªùng l√† symbol \"VNINDEX\" tr√™n exchange \"INDEX\"\n",
    "df = None\n",
    "try:\n",
    "    df = tv.get_hist(\n",
    "        symbol   = \"VNINDEX\",\n",
    "        exchange = \"INDEX\",\n",
    "        interval = Interval.in_daily,\n",
    "        n_bars   = 400\n",
    "    )\n",
    "    if df is not None and not df.empty:\n",
    "        df.index = df.index.tz_localize(None)\n",
    "        df = df.loc[START:END]\n",
    "        df.to_csv(\"VNINDEX_2024-01-01_to_2025-01-31_tv.csv\")\n",
    "        print(f\"üéâ Saved {len(df)} rows to VNINDEX_2024-01-01_to_2025-01-31_tv.csv\")\n",
    "    else:\n",
    "        raise ValueError(\"tvDatafeed kh√¥ng tr·∫£ v·ªÅ d·ªØ li·ªáu\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  tvDatafeed error: {e}\\n   Falling back to scraping‚Ä¶\")\n",
    "\n",
    "    # --- 2) Fallback: scrape Vietstock‚Äôs ‚ÄòL·ªãch s·ª≠ gi√°‚Äô c·ªßa VN-Index ---\n",
    "    def fetch_page(page):\n",
    "        url = (\n",
    "          \"https://finance.vietstock.vn/ty-so/vn-index/lich-su-gia?\"\n",
    "          \"languageid=2&page=\" + str(page)\n",
    "        )\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "        tbl  = soup.find(\"table\", class_=\"tblData\")\n",
    "        if not tbl:\n",
    "            return []\n",
    "        rows = []\n",
    "        for tr in tbl.tbody.find_all(\"tr\"):\n",
    "            cols = [td.text.strip().replace(\",\", \"\") for td in tr.find_all(\"td\")]\n",
    "            dt = datetime.strptime(cols[0], \"%d/%m/%Y\")\n",
    "            if dt < START:\n",
    "                return []\n",
    "            rows.append([\n",
    "                dt,\n",
    "                float(cols[1]),  # Open\n",
    "                float(cols[2]),  # High\n",
    "                float(cols[3]),  # Low\n",
    "                float(cols[4]),  # Close\n",
    "                int(cols[5])     # Volume\n",
    "            ])\n",
    "        return rows\n",
    "\n",
    "    all_rows = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        page_rows = fetch_page(page)\n",
    "        if not page_rows:\n",
    "            break\n",
    "        all_rows.extend(page_rows)\n",
    "        page += 1\n",
    "\n",
    "    df2 = pd.DataFrame(all_rows, columns=[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"])\n",
    "    df2 = df2.set_index(\"Date\").sort_index()\n",
    "    df2.to_csv(\"VNINDEX_2024-01-01_to_2025-01-31_vietstock.csv\")\n",
    "    print(f\"üéâ Scraped {len(df2)} rows to VNINDEX_2024-01-01_to_2025-01-31_vietstock.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ace_tools as tools\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu gi√° c·ªßa MWG\n",
    "df_mwg = pd.read_csv('MWG_2024-01-01_to_2025-01-31_tv.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# L·ªçc d·ªØ li·ªáu cho Qu√Ω 1/2025 (·ªü ƒë√¢y d·ªØ li·ªáu ch·ªâ t·ªõi 31/01/2025)\n",
    "df_q1 = df_mwg.loc['2025-01-01':'2025-01-31'].copy()\n",
    "\n",
    "# S·ªë c·ªï phi·∫øu l∆∞u h√†nh (outstanding shares) t·∫°i Q1/2025\n",
    "shares_outstanding = 14_622_441_770_000  # c·ªï phi·∫øu\n",
    "\n",
    "# T√≠nh Market Cap (VND) cho m·ªói ng√†y\n",
    "df_q1['market_cap'] = df_q1['close'] * shares_outstanding\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "tools.display_dataframe_to_user(\n",
    "    name=\"Market Cap c·ªßa MWG trong Qu√Ω 1/2025\",\n",
    "    dataframe=df_q1[['close', 'market_cap']].head(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c81d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
